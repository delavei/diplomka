sudo ./configure --enable-docker --enable-virt --enable-hadoop --enable-write-tsdb --enable-logfile --disable-all-plugins
sudo /opt/collectd/sbin/collectd -f
python diplomka/kod/tsddrain.py 4242 ./opentsdb/
sudo docker run -it debian  /bin/bash
sudo docker run -it ubuntu  /bin/bash


TEEEEEEEEEEEEEEEEEEEXT
Niektoré metriky sa v čase menia menej ako iné, napr. počet odoslaných chybných bajtov sa na sieťovom rozhraní nemení tak rýchlo ako počet odoslaných bajtov. V prípade, že
by teda bol prírastok nulový, bolo by možné metriku neodoslať   a uštriť záťaž? toto iba napísať, rieiši to opentsdb
Možný problém - dotazovanie na metriky v rôznych intervaloch, ale využívanie jedného pripojenia 

okomentovať, že nie všetky poskytované metriky má význam aj zberať

napisat o tom, ako sa vypocitava cpu load - podporit citaciou, ako sa to vlastne vyratava - napriklad aj ze zo zdrojaku

tabulka - nazvy metrik tak ako ich ukladam do databazy
metriky o konfigurácií zberať menej často 

hodnoty v tsd - ikrementalne vs. absolutne




cloudove technologie -reorganizacia, najprv uvod, ze  preco vlastne ich uvádzam metacentrum je hetergoenny, ma abc, teraz idem popisovat tiet technologie..
dat tam aj grid. vo virtualkach mozu byt kontajnery, ale zaujimaju nas len virtualky. obrazky - hadoop, metacentrum

prirovnanie s vlakmi - obmedzit

citacia - kvm, zen, iaas, paas, co je vytazenie zdrojov - ganglia bola akademická, najlepsie nieco tlacene. casova rada, tie metody
nejake nejasne o tom.

oddelit monitorovanie a uctovanie - napr. detekcia zdrojov a uzivatelov - ak su vhodne zbierane metriky a metedata, da sa to vyuzit
na accounting. mozem uvadzat misovu diplomku

cgroup - zaradiť neskôr, nie je to úplne monitorovanie, skôr kontrola prístupu k zdrojom. v gride server distribuuje ulohy, obali ich do 
 cgroup na konkretnom stroji a obcas sa tam pozrie, kolko zozerie
 
aktualne riesenia - podsekcie v programoch pomenovat rovnako, v uvode napisat ze co budem pri kazdom riesit
				  - collectd je nastroj na zber, nie cele riesenie, aj cgroup
				  - obrazok uviest do kontextu- ze co na nom je 
				  
brendan gregg linuxperf

je viac aplikacno kontajnerovych appiek, docker som vybral lebo je v metacentre

nestriedat cpu a procesor
analyza a navrh - vysoky monitorovaci vykon, skalovatelnost - mozno mat cisla, porovnat to s niecim a presne na com som to testoval
				a vsetko o merani - napr. tcollector






IMPLEMENTACIA
docker
aktualizovat verziu  dockeru- rozdiel v networkoch
robit pravidelne refresh zoznamu kontajnerov
config - host-majbe, refresh interval pre kontajnery
cpu kernelmode, usermode treba - odosielat

cJSON
nacitavanie unsigned long long (napr. docker system cpu usage)

hadoop
adresa klastra do konfiguracie
mena appiek, kde su konrolne vyrazy \n\t a tak sposobuju chaos v tsd. ked je meno appky nakonci, je to pohode

virt - aky cpu usage? ten co tam je je vyuzitie virtualneho, nie realneho (v dockeri je aj realny zrejme)
     - pridat cpu kernelmode a usermode - to tuším nejde
     - dorobit cpu load celého procesu virtuálky
     - dorobit pralaleizáciu dotazovania jednotlivých domén


















	
	monitorovacie softy
	\section{Cacti}
Cacti is a complete network graphing solution designed to harness the power of RRDTool's data storage and graphing functionality. Cacti provides a fast poller, advanced graph templating, multiple data acquisition methods, and user management features out of the box.
\cite{11}

\subsection{Ostatne} 
\begin{description}
\item[\emph{Zenoss}]
\item[\emph{Munin}]
\end{description}

\section{Scout}
Scout runs within Docker containers without any special configuration. \cite{scout}

\section{New Relic}
http://newrelic.com/docker



\section{Reakcia na dlhú odozvu modulu}
Ak je hodnota nejakej metriky mimo určitý rozsah, je generované hlásenie. Na to je možné reagovať.
Na situáciu, keď časť zodpovedná za zbieranie dát neodpovedá, je ale možné reagovať len reštartovaním celej monitorovacej aplikácie. Nie je možné jednotlivé pluginy ovládať nezávisle. 

V princípe nejde nijako odlíšiť, či daný modul čaká na údaje alebo došlo k chybe a modul neodpovedá. Preto bude potrebné vytvoriť niektoré pluginy tak, aby jedna časť bola neustále dostupná 
a reagovala na výzvy od riadiacej aplikácie. Bude definovaný časový interval na vrátenie hodnoty. V prípade ak plugin úspešne v časovom intervale zistil dané metrické dáta, vráti ich riadiacej aplikácií. V prípade, že v danom intervale plugin neobdržal metrické dáta,
vráti poslednú hodnotu. Zároveň sa nebudú vytvárať nové požiadavky na tento údaj. Tento časový interval si bude môcť užívateľ nastaviť pre každú sondu. Predmetom testovania bude zistiť, 
aký interval by bol vhodný pre tú ktorú sondu.

Ďalšou prahovou hodnotou bude počet opakovaní, pri ktorých plugin vracia poslednú hodnotu danej metriky. Ak dôjde k prekročeniu tejto hodnoty, bude reštartovaná celá monitorovacia aplikácia.


\subsection{Centrálny systém notifikácií a manažmentu zberných modulov}
Vyššie popísané riešenie predstavuje decentralizovanú architektúru. Každá zo sond funguje nezávisle, čo sťažuje prípadné mechanizmy konfigurácie
a riešenie krízových situácií ako napr. zastavenie činnosti démona. Toto je jeden z aspektov kde má navrch napr. systém Zabbix. Súčasťou
môjho riešenia bude zároveň aplikácia, ktorá bude spravovať konfigurácie jednotlivých inštancií collectd, umožní ich meniť a podľa toho ich reštartovať.
Umožní prehliadať notifikácie z jednotlivých sond a manuálne ovládať inštancie a ich moduly. To bude zároveň vyžadovať modifikáciu démona
collectd, ktorý v súčasnosti neumožňuje reštartovanie jednotlivých modulov.
\\Takýto systém konfigurácie môže mať význam pre lepšiu distribúciu monitorovacej záťaže, kedy skupina démonov môže odosielať dáta jednému 
démonovi časovej rady a iná skupina bude využívať iného časového démona.
